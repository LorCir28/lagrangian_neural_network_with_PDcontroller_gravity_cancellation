{"cells":[{"cell_type":"markdown","source":["# Global"],"metadata":{"id":"R6j8v1fbQxVF"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1uksv9wFQy99","executionInfo":{"status":"ok","timestamp":1688564111581,"user_tz":-120,"elapsed":20405,"user":{"displayName":"claudio schiavella","userId":"11074666491842407425"}},"outputId":"541d5a3c-7832-49e7-a2d1-86966f4c44c2"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"markdown","metadata":{"id":"4dlBAEyodLjY"},"source":["# LNN"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"fFWTbEPCdFpQ","executionInfo":{"status":"ok","timestamp":1688564115668,"user_tz":-120,"elapsed":345,"user":{"displayName":"claudio schiavella","userId":"11074666491842407425"}}},"outputs":[],"source":["# Generalized Lagrangian Networks | 2020\n","# Miles Cranmer, Sam Greydanus, Stephan Hoyer (...)\n","\n","import jax\n","import jax.numpy as jnp\n","from jax.experimental.ode import odeint\n","from functools import partial\n","\n","# unconstrained equation of motion\n","def unconstrained_eom(model, state, t=None):\n","  q, q_t = jnp.split(state, 2)\n","  return model(q, q_t)\n","\n","# lagrangian equation of motion\n","def lagrangian_eom(lagrangian, state, t=None):\n","  q, q_t = jnp.split(state, 2)\n","  #Note: the following line assumes q is an angle. Delete it for problems other than double pendulum.\n","  q = q % (2*jnp.pi)\n","  q_tt = (jnp.linalg.pinv(jax.hessian(lagrangian, 1)(q, q_t))\n","          @ (jax.grad(lagrangian, 0)(q, q_t)\n","             - jax.jacobian(jax.jacobian(lagrangian, 1), 0)(q, q_t) @ q_t))\n","  dt = 1e-1\n","  return dt*jnp.concatenate([q_t, q_tt])\n","\n","def raw_lagrangian_eom(lagrangian, state, t=None):\n","  q, q_t = jnp.split(state, 2)\n","  q = q % (2*jnp.pi)\n","  q_tt = (jnp.linalg.pinv(jax.hessian(lagrangian, 1)(q, q_t))\n","          @ (jax.grad(lagrangian, 0)(q, q_t)\n","             - jax.jacobian(jax.jacobian(lagrangian, 1), 0)(q, q_t) @ q_t))\n","  return jnp.concatenate([q_t, q_tt])\n","\n","def lagrangian_eom_rk4(lagrangian, state, n_updates, Dt=1e-1, t=None):\n","    @jax.jit\n","    def cur_fnc(state):\n","        q, q_t = jnp.split(state, 2)\n","        q = q % (2*jnp.pi)\n","        q_tt = (jnp.linalg.pinv(jax.hessian(lagrangian, 1)(q, q_t))\n","                 @ (jax.grad(lagrangian, 0)(q, q_t)\n","                 - jax.jacobian(jax.jacobian(lagrangian, 1), 0)(q, q_t) @ q_t))\n","        return jnp.concatenate([q_t, q_tt])\n","\n","    @jax.jit\n","    def get_update(update):\n","        dt = Dt/n_updates\n","        cstate = state + update\n","        k1 = dt*cur_fnc(cstate)\n","        k2 = dt*cur_fnc(cstate + k1/2)\n","        k3 = dt*cur_fnc(cstate + k2/2)\n","        k4 = dt*cur_fnc(cstate + k3)\n","        return update + 1.0/6.0 * (k1 + 2*k2 + 2*k3 + k4)\n","\n","    update = 0\n","    for _ in range(n_updates):\n","        update = get_update(update)\n","    return update\n","\n","\n","def solve_dynamics(dynamics_fn, initial_state, is_lagrangian=True, **kwargs):\n","  eom = lagrangian_eom if is_lagrangian else unconstrained_eom\n","\n","  # We currently run odeint on CPUs only, because its cost is dominated by\n","  # control flow, which is slow on GPUs.\n","  @partial(jax.jit, backend='cpu')\n","  def f(initial_state):\n","    return odeint(partial(eom, dynamics_fn), initial_state, **kwargs)\n","  return f(initial_state)\n","\n","\n","def custom_init(init_params, seed=0):\n","    \"\"\"Do an optimized LNN initialization for a simple uniform-width MLP\"\"\"\n","    import numpy as np\n","    new_params = []\n","    rng = jax.random.PRNGKey(seed)\n","    i = 0\n","    number_layers = len([0 for l1 in init_params if len(l1) != 0])\n","    for l1 in init_params:\n","        if (len(l1)) == 0: new_params.append(()); continue\n","        new_l1 = []\n","        for l2 in l1:\n","            if len(l2.shape) == 1:\n","                #Zero init biases\n","                new_l1.append(jnp.zeros_like(l2))\n","            else:\n","                n = max(l2.shape)\n","                first = int(i == 0)\n","                last = int(i == number_layers - 1)\n","                mid = int((i != 0) * (i != number_layers - 1))\n","                mid *= i\n","\n","                std = 1.0/np.sqrt(n)\n","                std *= 2.2*first + 0.58*mid + n*last\n","\n","                if std == 0:\n","                    raise NotImplementedError(\"Wrong dimensions for MLP\")\n","\n","                new_l1.append(jax.random.normal(rng, l2.shape)*std)\n","                rng += 1\n","                i += 1\n","\n","        new_params.append(new_l1)\n","\n","    return new_params"]},{"cell_type":"markdown","metadata":{"id":"-hTiSIu4d1Rc"},"source":["# Utils"]},{"cell_type":"code","execution_count":13,"metadata":{"id":"5D81fQLgdFW3","executionInfo":{"status":"ok","timestamp":1688564116435,"user_tz":-120,"elapsed":5,"user":{"displayName":"claudio schiavella","userId":"11074666491842407425"}}},"outputs":[],"source":["# Generalized Lagrangian Networks | 2020\n","# Miles Cranmer, Sam Greydanus, Stephan Hoyer (...)\n","\n","import jax.numpy as jnp\n","import pickle\n","\n","def wrap_coords(state):\n","  # wrap generalized coordinates to [-pi, pi]\n","  return jnp.concatenate([(state[:2] + jnp.pi) % (2 * jnp.pi) - jnp.pi, state[2:]])\n","\n","def rk4_step(f, x, t, h):\n","  # one step of Runge-Kutta integration\n","  k1 = h * f(x, t)\n","  k2 = h * f(x + k1/2, t + h/2)\n","  k3 = h * f(x + k2/2, t + h/2)\n","  k4 = h * f(x + k3, t + h)\n","  return x + 1/6 * (k1 + 2 * k2 + 2 * k3 + k4)\n","\n","def radial2cartesian(t1, t2, l1, l2):\n","  # Convert from radial to Cartesian coordinates.\n","  x1 = l1 * jnp.sin(t1)\n","  y1 = -l1 * jnp.cos(t1)\n","  x2 = x1 + l2 * jnp.sin(t2)\n","  y2 = y1 - l2 * jnp.cos(t2)\n","  return x1, y1, x2, y2\n","\n","def write_to(data, path):\n","  with open(path, 'wb') as f:\n","    pickle.dump(data, f, protocol=pickle.HIGHEST_PROTOCOL)\n","\n","def read_from(path):\n","  with open(path, 'rb') as f:\n","    data = pickle.load(f)\n","  return data"]},{"cell_type":"code","execution_count":13,"metadata":{"id":"6XRq_Upmcetp","executionInfo":{"status":"ok","timestamp":1688564116436,"user_tz":-120,"elapsed":4,"user":{"displayName":"claudio schiavella","userId":"11074666491842407425"}}},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"57OeKsfceAQT"},"source":["# Physics (double trunc)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AGvdboD-eCfQ"},"outputs":[],"source":["# Generalized Lagrangian Networks | 2020\n","# Miles Cranmer, Sam Greydanus, Stephan Hoyer (...)\n","\n","import jax\n","import jax.numpy as jnp\n","from jax import jit\n","\n","@jit\n","def kinetic_energy(q, q_dot, m1=1, m2=1, l1=1, l2=1, g=9.8):\n","  (t1, t2), (w1, w2) = q, q_dot\n","\n","  T1 = 0.5 * m1 * (l1 * w1)**2\n","  T2 = 0.5 * m2 * ((l1 * w1)**2 + (l2 * w2)**2 + 2 * l1 * l2 * w1 * w2 * jnp.cos(t1 - t2))\n","  T = T1 + T2\n","  return T\n","\n","@jit\n","def potential_energy(q, q_dot, m1=1, m2=1, l1=1, l2=1, g=9.8):\n","  (t1, t2), (w1, w2) = q, q_dot\n","\n","  y1 = -l1 * jnp.cos(t1)\n","  y2 = y1 - l2 * jnp.cos(t2)\n","  V = m1 * g * y1 + m2 * g * y2\n","  return V\n","\n","# Double pendulum lagrangian\n","@jit\n","def lagrangian_fn(q, q_dot, m1=1, m2=1, l1=1, l2=1, g=9.8):\n","  (t1, t2), (w1, w2) = q, q_dot\n","\n","  T = kinetic_energy(q, q_dot, m1=1, m2=1, l1=1, l2=1, g=9.8)\n","  V = potential_energy(q, q_dot, m1=1, m2=1, l1=1, l2=1, g=9.8)\n","  return T - V\n","\n","# Double pendulum lagrangian\n","@jit\n","def hamiltonian_fn(q, q_dot, m1=1, m2=1, l1=1, l2=1, g=9.8):\n","  (t1, t2), (w1, w2) = q, q_dot\n","\n","  T = kinetic_energy(q, q_dot, m1=1, m2=1, l1=1, l2=1, g=9.8)\n","  V = potential_energy(q, q_dot, m1=1, m2=1, l1=1, l2=1, g=9.8)\n","  return T + V\n","\n","\n","# Double pendulum dynamics via analytical forces taken from Diego's blog\n","#\n","# def analytical_fn(state, t=0, m1=1, m2=1, l1=1, l2=1, g=9.8):\n","#   t1, t2, w1, w2 = state\n","#   a1 = (l2 / l1) * (m2 / (m1 + m2)) * jnp.cos(t1 - t2)\n","#   a2 = (l1 / l2) * jnp.cos(t1 - t2)\n","#   f1 = -(l2 / l1) * (m2 / (m1 + m2)) * (w2**2) * jnp.sin(t1 - t2) - (g / l1) * jnp.sin(t1)\n","#   f2 = (l1 / l2) * (w1**2) * jnp.sin(t1 - t2) - (g / l2) * jnp.sin(t2)\n","#   g1 = (f1 - a1 * f2) / (1 - a1 * a2)\n","#   g2 = (f2 - a2 * f1) / (1 - a1 * a2)\n","#   return jnp.stack([w1, w2, g1, g2])\n","\n","@jit\n","def analytical_fn(state, t=0, m1=1, m2=1, l1=1, l2=1, g=9.8,d1=1,I=1):\n","  t1, t2, w1, w2 = state\n","  a1 = 0\n","  a2 = (l1 / l2) * jnp.cos(t1 - t2)\n","  f1 = -m1*g*d1*jnp.cos(t1)/(I+m1*d1**2)\n","  f2 = (l1 / l2) * (w1**2) * jnp.sin(t1 - t2) - (g / l2) * jnp.sin(t2)\n","  g1 = (f1 - a1 * f2) / (1 - a1 * a2)\n","  g2 = (f2 - a2 * f1) / (1 - a1 * a2)\n","  return jnp.stack([w1, 0, g1, 0])"]},{"cell_type":"markdown","metadata":{"id":"YGPC8lulC8Ui"},"source":["# Physics (single)"]},{"cell_type":"code","execution_count":14,"metadata":{"id":"LlbAyM-OC8U2","executionInfo":{"status":"ok","timestamp":1688564118345,"user_tz":-120,"elapsed":231,"user":{"displayName":"claudio schiavella","userId":"11074666491842407425"}}},"outputs":[],"source":["# Generalized Lagrangian Networks | 2020\n","# Miles Cranmer, Sam Greydanus, Stephan Hoyer (...)\n","\n","import jax\n","import jax.numpy as jnp\n","from jax import jit\n","\n","@jit\n","def kinetic_energy(q, q_dot, m1=1, m2=1, l1=1, l2=1, g=9.8, I=1, d1=1):\n","  t1, w1 = q, q_dot\n","  T = 0.5 * (I + m1*(d1**2))*(w1**2)\n","  return T\n","\n","@jit\n","def potential_energy(q, q_dot, m1=1, m2=1, l1=1, l2=1, g=9.8, d1=1):\n","  t1, w1 = q, q_dot\n","  V = m1*g*l1*jnp.sin(t1)\n","  return V\n","\n","# Double pendulum lagrangian\n","@jit\n","def lagrangian_fn(q, q_dot, m1=1, m2=1, l1=1, l2=1, g=9.8):\n","  T = kinetic_energy(q, q_dot, m1=1, m2=1, l1=1, l2=1, g=9.8)\n","  V = potential_energy(q, q_dot, m1=1, m2=1, l1=1, l2=1, g=9.8)\n","  return jnp.sum(T - V)\n","\n","def analytical_fn(state, t=0, m1=1, m2=1, l1=1, l2=1, g=9.8,d1=1,I=1):\n","  t1, w1 = state\n","  a1 = 0\n","  f1 = -m1*g*d1*jnp.cos(t1)/(I+m1*d1**2)\n","  g1 = f1\n","  return jnp.stack([w1,g1])"]},{"cell_type":"markdown","metadata":{"id":"ww1DfR68db4y"},"source":["# Data (double trunc)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6sOyFVymdFhu"},"outputs":[],"source":["# Generalized Lagrangian Networks | 2020\n","# Miles Cranmer, Sam Greydanus, Stephan Hoyer (...)\n","\n","import jax\n","import jax.numpy as jnp\n","from jax import random\n","import numpy as np # get rid of this eventually\n","from jax.experimental.ode import odeint\n","from functools import partial # reduces arguments to function by making some subset implicit\n","\n","import os, sys\n","#THIS_DIR = os.path.dirname(os.path.abspath(__file__))\n","#PARENT_DIR = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))\n","#sys.path.append(PARENT_DIR)\n","\n","#HACK\n","#from .physics import lagrangian_fn, analytical_fn\n","\n","\n","\n","@partial(jax.jit, backend='cpu')\n","def get_trajectory(y0, times, use_lagrangian=True, **kwargs):\n","  # frames = int(fps*(t_span[1]-t_span[0]))\n","  # times = jnp.linspace(t_span[0], t_span[1], frames)\n","  # y0 = np.array([3*np.pi/7, 3*np.pi/4, 0, 0], dtype=np.float32)\n","  if use_lagrangian:\n","    y = solve_dynamics(lagrangian_fn, y0, t=times, is_lagrangian=True, rtol=1e-10, atol=1e-10, **kwargs)\n","  else:\n","    y = odeint(analytical_fn, y0, t=times, rtol=1e-10, atol=1e-10, **kwargs)\n","  return y\n","\n","@partial(jax.jit, backend='cpu')\n","def get_trajectory_lagrangian(y0, times, **kwargs):\n","  return solve_dynamics(lagrangian_fn, y0, t=times, is_lagrangian=True, rtol=1e-10, atol=1e-10, **kwargs)\n","\n","@partial(jax.jit, backend='cpu')\n","def get_trajectory_analytic(y0, times, **kwargs):\n","    return odeint(analytical_fn, y0, t=times, rtol=1e-10, atol=1e-10, **kwargs)\n","\n","def get_dataset(seed=0, samples=1, t_span=[0,2000], fps=1, test_split=0.5, **kwargs):\n","    data = {'meta': locals()}\n","\n","    # randomly sample inputs\n","    np.random.seed(seed)\n","\n","    frames = int(fps*(t_span[1]-t_span[0]))\n","    times = np.linspace(t_span[0], t_span[1], frames)\n","    y0 = np.array([3*np.pi/7, 3*np.pi/4, 0, 0], dtype=np.float32)\n","\n","    xs, dxs = [], []\n","    vfnc = jax.jit(jax.vmap(analytical_fn))\n","    for s in range(samples):\n","      x = get_trajectory(y0, times, **kwargs)\n","      dx = vfnc(x)\n","      #print(x)\n","      #print(dx)\n","      #print(\"-----------------\")\n","      #a = input()\n","\n","      xs.append(x) ; dxs.append(dx)\n","\n","    data['x'] = jax.vmap(wrap_coords)(jnp.concatenate(xs))\n","    data['dx'] = jnp.concatenate(dxs)\n","    data['t'] = times\n","\n","    # make a train/test split\n","    split_ix = int(len(data['x']) * test_split)\n","    split_data = {}\n","    for k in ['x', 'dx', 't']:\n","        split_data[k], split_data['test_' + k] = data[k][:split_ix], data[k][split_ix:]\n","    data = split_data\n","    return data"]},{"cell_type":"markdown","metadata":{"id":"rDbPda54DL7o"},"source":["# Data (single)"]},{"cell_type":"code","execution_count":15,"metadata":{"id":"8rh8sMCCDL76","executionInfo":{"status":"ok","timestamp":1688564120437,"user_tz":-120,"elapsed":353,"user":{"displayName":"claudio schiavella","userId":"11074666491842407425"}}},"outputs":[],"source":["# Generalized Lagrangian Networks | 2020\n","# Miles Cranmer, Sam Greydanus, Stephan Hoyer (...)\n","\n","import jax\n","import jax.numpy as jnp\n","from jax import random\n","import numpy as np # get rid of this eventually\n","from jax.experimental.ode import odeint\n","from functools import partial # reduces arguments to function by making some subset implicit\n","\n","import os, sys\n","#THIS_DIR = os.path.dirname(os.path.abspath(__file__))\n","#PARENT_DIR = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))\n","#sys.path.append(PARENT_DIR)\n","\n","#HACK\n","#from .physics import lagrangian_fn, analytical_fn\n","\n","\n","\n","@partial(jax.jit, backend='cpu')\n","def get_trajectory(y0, times, use_lagrangian=True, **kwargs):\n","  # frames = int(fps*(t_span[1]-t_span[0]))\n","  # times = jnp.linspace(t_span[0], t_span[1], frames)\n","  # y0 = np.array([3*np.pi/7, 3*np.pi/4, 0, 0], dtype=np.float32)\n","  if use_lagrangian:\n","    y = solve_dynamics(lagrangian_fn, y0, t=times, is_lagrangian=True, rtol=1e-10, atol=1e-10, **kwargs)\n","  else:\n","    y = odeint(analytical_fn, y0, t=times, rtol=1e-10, atol=1e-10, **kwargs)\n","  return y\n","\n","@partial(jax.jit, backend='cpu')\n","def get_trajectory_lagrangian(y0, times, **kwargs):\n","  return solve_dynamics(lagrangian_fn, y0, t=times, is_lagrangian=True, rtol=1e-10, atol=1e-10, **kwargs)\n","\n","@partial(jax.jit, backend='cpu')\n","def get_trajectory_analytic(y0, times, **kwargs):\n","    return odeint(analytical_fn, y0, t=times, rtol=1e-10, atol=1e-10, **kwargs)\n","\n","def get_dataset(seed=0, samples=1, t_span=[0,2000], fps=1, test_split=0.5, **kwargs):\n","    data = {'meta': locals()}\n","\n","    # randomly sample inputs\n","    np.random.seed(seed)\n","\n","    frames = int(fps*(t_span[1]-t_span[0]))\n","    times = np.linspace(t_span[0], t_span[1], frames)\n","    y0 = np.array([3*np.pi/7, 0], dtype=np.float32)\n","\n","    xs, dxs = [], []\n","    vfnc = jax.jit(jax.vmap(analytical_fn))\n","    for s in range(samples):\n","      x = get_trajectory(y0, times, **kwargs)\n","      dx = vfnc(x)\n","      #print(x)\n","      #print(dx)\n","      #print(\"-----------------\")\n","      #a = input()\n","\n","      xs.append(x) ; dxs.append(dx)\n","\n","    data['x'] = jax.vmap(wrap_coords)(jnp.concatenate(xs))\n","    data['dx'] = jnp.concatenate(dxs)\n","    data['t'] = times\n","\n","    # make a train/test split\n","    split_ix = int(len(data['x']) * test_split)\n","    split_data = {}\n","    for k in ['x', 'dx', 't']:\n","        split_data[k], split_data['test_' + k] = data[k][:split_ix], data[k][split_ix:]\n","    data = split_data\n","    return data"]},{"cell_type":"markdown","metadata":{"id":"umAM16BueXwf"},"source":["# Models"]},{"cell_type":"code","execution_count":16,"metadata":{"id":"fpIG9arWeaki","executionInfo":{"status":"ok","timestamp":1688564121283,"user_tz":-120,"elapsed":4,"user":{"displayName":"claudio schiavella","userId":"11074666491842407425"}}},"outputs":[],"source":["# Generalized Lagrangian Networks | 2020\n","# Miles Cranmer, Sam Greydanus, Stephan Hoyer (...)\n","\n","from jax.example_libraries import stax\n","\n","def mlp(args):\n","    return stax.serial(\n","        stax.Dense(args.input_dim),\n","        stax.Softplus,\n","        stax.Dense(args.hidden_dim),\n","        stax.Softplus,\n","        stax.Dense(args.output_dim),\n","    )\n","\n","def pixel_encoder(args):\n","    return stax.serial(\n","        stax.Dense(args.ae_hidden_dim),\n","        stax.Softplus,\n","        stax.Dense(args.ae_latent_dim),\n","    )\n","\n","def pixel_decoder(args):\n","    return stax.serial(\n","        stax.Dense(args.ae_hidden_dim),\n","        stax.Softplus,\n","        stax.Dense(args.ae_input_dim),\n","    )"]},{"cell_type":"markdown","metadata":{"id":"8dDNk_2_ekw6"},"source":["# Train"]},{"cell_type":"code","execution_count":18,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Hid7I-0yel2t","outputId":"737d970c-4660-4717-9ab9-1bd19f44793d","executionInfo":{"status":"ok","timestamp":1688564646795,"user_tz":-120,"elapsed":216002,"user":{"displayName":"claudio schiavella","userId":"11074666491842407425"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["iteration=0, train_loss=8.042976, test_loss=8.119452\n","iteration=1000, train_loss=1.815252, test_loss=1.813355\n","iteration=2000, train_loss=0.788143, test_loss=0.758430\n","iteration=3000, train_loss=0.395477, test_loss=0.364354\n","iteration=4000, train_loss=0.307840, test_loss=0.285225\n","iteration=5000, train_loss=0.269882, test_loss=0.251392\n","iteration=6000, train_loss=0.249436, test_loss=0.231139\n","iteration=7000, train_loss=0.228155, test_loss=0.208802\n","iteration=8000, train_loss=0.204888, test_loss=0.184361\n","iteration=9000, train_loss=0.179857, test_loss=0.159790\n","iteration=10000, train_loss=0.161562, test_loss=0.142296\n","iteration=11000, train_loss=0.150405, test_loss=0.131101\n","iteration=12000, train_loss=0.138386, test_loss=0.119237\n","iteration=13000, train_loss=0.129013, test_loss=0.110255\n","iteration=14000, train_loss=0.122907, test_loss=0.104504\n","iteration=15000, train_loss=0.118429, test_loss=0.100456\n","iteration=16000, train_loss=0.114820, test_loss=0.097087\n","iteration=17000, train_loss=0.112503, test_loss=0.095069\n","iteration=18000, train_loss=0.111991, test_loss=0.094596\n","iteration=19000, train_loss=0.111226, test_loss=0.093880\n","iteration=20000, train_loss=0.110117, test_loss=0.092832\n","iteration=21000, train_loss=0.108576, test_loss=0.091380\n","iteration=22000, train_loss=0.106786, test_loss=0.089767\n","iteration=23000, train_loss=0.105027, test_loss=0.088233\n","iteration=24000, train_loss=0.103297, test_loss=0.086762\n","iteration=25000, train_loss=0.101587, test_loss=0.085341\n","iteration=26000, train_loss=0.099920, test_loss=0.083951\n","iteration=27000, train_loss=0.098301, test_loss=0.082646\n","iteration=28000, train_loss=0.096737, test_loss=0.081400\n","iteration=29000, train_loss=0.095238, test_loss=0.080207\n","iteration=30000, train_loss=0.093811, test_loss=0.079082\n","iteration=31000, train_loss=0.092455, test_loss=0.078038\n","iteration=32000, train_loss=0.091189, test_loss=0.077111\n","iteration=33000, train_loss=0.089938, test_loss=0.076088\n","iteration=34000, train_loss=0.089490, test_loss=0.075739\n","iteration=35000, train_loss=0.089336, test_loss=0.075611\n","iteration=36000, train_loss=0.089149, test_loss=0.075453\n","iteration=37000, train_loss=0.088930, test_loss=0.075264\n","iteration=38000, train_loss=0.088680, test_loss=0.075044\n","iteration=39000, train_loss=0.088418, test_loss=0.074814\n","iteration=40000, train_loss=0.088160, test_loss=0.074591\n","iteration=41000, train_loss=0.087910, test_loss=0.074373\n","iteration=42000, train_loss=0.087664, test_loss=0.074157\n","iteration=43000, train_loss=0.087421, test_loss=0.073944\n","iteration=44000, train_loss=0.087181, test_loss=0.073736\n","iteration=45000, train_loss=0.086944, test_loss=0.073524\n","iteration=46000, train_loss=0.086708, test_loss=0.073317\n","iteration=47000, train_loss=0.086474, test_loss=0.073111\n","iteration=48000, train_loss=0.086241, test_loss=0.072908\n","iteration=49000, train_loss=0.086011, test_loss=0.072706\n","iteration=50000, train_loss=0.085780, test_loss=0.072505\n"]}],"source":["# Generalized Lagrangian Networks | 2020\n","# Miles Cranmer, Sam Greydanus, Stephan Hoyer (...)\n","\n","import jax\n","import jax.numpy as jnp\n","import numpy as np # get rid of this eventually\n","import argparse\n","from jax.experimental.ode import odeint\n","from functools import partial # reduces arguments to function by making some subset implicit\n","\n","from jax.example_libraries import stax\n","from jax.example_libraries import optimizers\n","\n","import os, sys, time\n","#THIS_DIR = os.path.dirname(os.path.abspath(__file__))\n","#PARENT_DIR = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))\n","#sys.path.append(PARENT_DIR)\n","\n","def get_args():\n","    return {'input_dim': 2,\n","           'hidden_dim': 128,\n","           'output_dim': 2,\n","           'dataset_size': 3000,\n","           'learn_rate': 1e-3,\n","           'batch_size': 100,\n","           'test_every': 10,\n","           'num_batches': 500,\n","           'name': 'dblpend',\n","           'model': 'baseline_nn',\n","           'verbose': True,\n","           'seed': 1,\n","           'save_dir': '.'}\n","\n","class ObjectView(object):\n","    def __init__(self, d): self.__dict__ = d\n","\n","\n","# replace the lagrangian with a parameteric model\n","def learned_dynamics(params):\n","  def dynamics(q, q_t):\n","    #assert q.shape == (2,)\n","    state = wrap_coords(jnp.concatenate([q, q_t]))\n","    return nn_forward_fn(params, state)\n","  return dynamics\n","\n","@jax.jit\n","def gln_loss(params, batch, time_step=None):\n","  state, targets = batch\n","  preds = jax.vmap(partial(lagrangian_eom, learned_dynamics(params)))(state)\n","  return jnp.mean((preds - targets) ** 2)\n","\n","@jax.jit\n","def baseline_loss(params, batch, time_step=None):\n","  state, targets = batch\n","  preds = jax.vmap(partial(unconstrained_eom, learned_dynamics(params)))(state)\n","  return jnp.mean((preds - targets) ** 2)\n","\n","\n","def train(args, model, data):\n","  global opt_update, get_params, nn_forward_fn\n","  (nn_forward_fn, init_params) = model\n","  data = {k: jax.device_put(v) if type(v) is np.ndarray else v for k,v in data.items()}\n","  time.sleep(2)\n","\n","  # choose our loss function\n","  if args.model == 'gln':\n","    loss = gln_loss\n","  elif args.model == 'baseline_nn':\n","    loss = baseline_loss\n","  else:\n","    raise(ValueError)\n","\n","  @jax.jit\n","  def update_derivative(i, opt_state, batch):\n","    params = get_params(opt_state)\n","    return opt_update(i, jax.grad(loss)(params, batch, None), opt_state)\n","\n","  # make an optimizer\n","  opt_init, opt_update, get_params = optimizers.adam(\n","    lambda t: jnp.select([t < args.batch_size*(args.num_batches//3),\n","                          t < args.batch_size*(2*args.num_batches//3),\n","                          t > args.batch_size*(2*args.num_batches//3)],\n","                         [args.learn_rate, args.learn_rate/10, args.learn_rate/100]))\n","  opt_state = opt_init(init_params)\n","\n","  train_losses, test_losses = [], []\n","  for iteration in range(args.batch_size*args.num_batches + 1):\n","    if iteration % args.batch_size == 0:\n","      params = get_params(opt_state)\n","      train_loss = loss(params, (data['x'], data['dx']))\n","      train_losses.append(train_loss)\n","      test_loss = loss(params, (data['test_x'], data['test_dx']))\n","      test_losses.append(test_loss)\n","      if iteration % (args.batch_size*args.test_every) == 0:\n","        print(f\"iteration={iteration}, train_loss={train_loss:.6f}, test_loss={test_loss:.6f}\")\n","    opt_state = update_derivative(iteration, opt_state, (data['x'], data['dx']))\n","\n","  params = get_params(opt_state)\n","  return params, train_losses, test_losses\n","\n","if __name__ == \"__main__\":\n","  args = ObjectView(get_args())\n","  get_dataset(t_span=[0,args.dataset_size], fps=1, samples=1)\n","\n","  rng = jax.random.PRNGKey(args.seed)\n","  init_random_params, nn_forward_fn = mlp(args)\n","  _, init_params = init_random_params(rng, (-1, 2)) #4\n","  model = (nn_forward_fn, init_params)\n","  data = get_dataset(t_span=[0,args.dataset_size], fps=1, samples=1)\n","\n","  result = train(args, model, data)\n","  pickle.dump({'params': result[0], 'args': args},open('/content/drive/MyDrive/Robotics2_project/params_for_loss_{}_nupdates=1.pkl'.format(min(result[2])), 'wb'))"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":["4dlBAEyodLjY","-hTiSIu4d1Rc","57OeKsfceAQT","ww1DfR68db4y","umAM16BueXwf"],"provenance":[],"authorship_tag":"ABX9TyMz2VK46VPlaQGdTzGpk4e8"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}