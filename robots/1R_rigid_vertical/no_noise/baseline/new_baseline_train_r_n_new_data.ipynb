{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Global"
      ],
      "metadata": {
        "id": "aSH3UDxeii7B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LWPpOnpEilLB",
        "outputId": "c278366e-c964-4525-eff0-62d7d7e392f1"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4dlBAEyodLjY"
      },
      "source": [
        "# LNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "fFWTbEPCdFpQ"
      },
      "outputs": [],
      "source": [
        "# Generalized Lagrangian Networks | 2020\n",
        "# Miles Cranmer, Sam Greydanus, Stephan Hoyer (...)\n",
        "\n",
        "import jax\n",
        "import jax.numpy as jnp\n",
        "from jax.experimental.ode import odeint\n",
        "from functools import partial\n",
        "\n",
        "# unconstrained equation of motion\n",
        "def unconstrained_eom(model, state, t=None):\n",
        "  q, q_t = jnp.split(state, 2)\n",
        "  return jnp.concatenate([q_t, model(q, q_t).reshape([1])])\n",
        "\n",
        "# lagrangian equation of motion\n",
        "def lagrangian_eom(lagrangian, state, t=None):\n",
        "  q, q_t = jnp.split(state, 2)\n",
        "  #Note: the following line assumes q is an angle. Delete it for problems other than double pendulum.\n",
        "  q = q % (2*jnp.pi)\n",
        "  q_tt = (jnp.linalg.pinv(jax.hessian(lagrangian, 1)(q, q_t))\n",
        "          @ (jax.grad(lagrangian, 0)(q, q_t)\n",
        "             - jax.jacobian(jax.jacobian(lagrangian, 1), 0)(q, q_t) @ q_t))\n",
        "  dt = 1e-1\n",
        "  return dt*jnp.concatenate([q_t, q_tt])\n",
        "\n",
        "def raw_lagrangian_eom(lagrangian, state, t=None):\n",
        "  q, q_t = jnp.split(state, 2)\n",
        "  q = q % (2*jnp.pi)\n",
        "  q_tt = (jnp.linalg.pinv(jax.hessian(lagrangian, 1)(q, q_t))\n",
        "          @ (jax.grad(lagrangian, 0)(q, q_t)\n",
        "             - jax.jacobian(jax.jacobian(lagrangian, 1), 0)(q, q_t) @ q_t))\n",
        "  return jnp.concatenate([q_t, q_tt])\n",
        "\n",
        "def lagrangian_eom_rk4(lagrangian, state, n_updates, Dt=1e-1, t=None):\n",
        "    @jax.jit\n",
        "    def cur_fnc(state):\n",
        "        q, q_t = jnp.split(state, 2)\n",
        "        q = q % (2*jnp.pi)\n",
        "        q_tt = (jnp.linalg.pinv(jax.hessian(lagrangian, 1)(q, q_t))\n",
        "                 @ (jax.grad(lagrangian, 0)(q, q_t)\n",
        "                 - jax.jacobian(jax.jacobian(lagrangian, 1), 0)(q, q_t) @ q_t))\n",
        "        return jnp.concatenate([q_t, q_tt])\n",
        "\n",
        "    @jax.jit\n",
        "    def get_update(update):\n",
        "        dt = Dt/n_updates\n",
        "        cstate = state + update\n",
        "        k1 = dt*cur_fnc(cstate)\n",
        "        k2 = dt*cur_fnc(cstate + k1/2)\n",
        "        k3 = dt*cur_fnc(cstate + k2/2)\n",
        "        k4 = dt*cur_fnc(cstate + k3)\n",
        "        return update + 1.0/6.0 * (k1 + 2*k2 + 2*k3 + k4)\n",
        "\n",
        "    update = 0\n",
        "    for _ in range(n_updates):\n",
        "        update = get_update(update)\n",
        "    return update\n",
        "\n",
        "\n",
        "def solve_dynamics(dynamics_fn, initial_state, is_lagrangian=True, **kwargs):\n",
        "  eom = lagrangian_eom if is_lagrangian else unconstrained_eom\n",
        "\n",
        "  # We currently run odeint on CPUs only, because its cost is dominated by\n",
        "  # control flow, which is slow on GPUs.\n",
        "  @partial(jax.jit, backend='cpu')\n",
        "  def f(initial_state):\n",
        "    return odeint(partial(eom, dynamics_fn), initial_state, **kwargs)\n",
        "  return f(initial_state)\n",
        "\n",
        "\n",
        "def custom_init(init_params, seed=0):\n",
        "    \"\"\"Do an optimized LNN initialization for a simple uniform-width MLP\"\"\"\n",
        "    import numpy as np\n",
        "    new_params = []\n",
        "    rng = jax.random.PRNGKey(seed)\n",
        "    i = 0\n",
        "    number_layers = len([0 for l1 in init_params if len(l1) != 0])\n",
        "    for l1 in init_params:\n",
        "        if (len(l1)) == 0: new_params.append(()); continue\n",
        "        new_l1 = []\n",
        "        for l2 in l1:\n",
        "            if len(l2.shape) == 1:\n",
        "                #Zero init biases\n",
        "                new_l1.append(jnp.zeros_like(l2))\n",
        "            else:\n",
        "                n = max(l2.shape)\n",
        "                first = int(i == 0)\n",
        "                last = int(i == number_layers - 1)\n",
        "                mid = int((i != 0) * (i != number_layers - 1))\n",
        "                mid *= i\n",
        "\n",
        "                std = 1.0/np.sqrt(n)\n",
        "                std *= 2.2*first + 0.58*mid + n*last\n",
        "\n",
        "                if std == 0:\n",
        "                    raise NotImplementedError(\"Wrong dimensions for MLP\")\n",
        "\n",
        "                new_l1.append(jax.random.normal(rng, l2.shape)*std)\n",
        "                rng += 1\n",
        "                i += 1\n",
        "\n",
        "        new_params.append(new_l1)\n",
        "\n",
        "    return new_params\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-hTiSIu4d1Rc"
      },
      "source": [
        "# Utils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "5D81fQLgdFW3"
      },
      "outputs": [],
      "source": [
        "# Generalized Lagrangian Networks | 2020\n",
        "# Miles Cranmer, Sam Greydanus, Stephan Hoyer (...)\n",
        "\n",
        "import jax.numpy as jnp\n",
        "import pickle\n",
        "\n",
        "def wrap_coords(state):\n",
        "  # wrap generalized coordinates to [-pi, pi]\n",
        "  return jnp.concatenate([(state[:2] + jnp.pi) % (2 * jnp.pi) - jnp.pi, state[2:]])\n",
        "\n",
        "def rk4_step(f, x, t, h):\n",
        "  # one step of Runge-Kutta integration\n",
        "  k1 = h * f(x, t)\n",
        "  k2 = h * f(x + k1/2, t + h/2)\n",
        "  k3 = h * f(x + k2/2, t + h/2)\n",
        "  k4 = h * f(x + k3, t + h)\n",
        "  return x + 1/6 * (k1 + 2 * k2 + 2 * k3 + k4)\n",
        "\n",
        "def radial2cartesian(t1, t2, l1, l2):\n",
        "  # Convert from radial to Cartesian coordinates.\n",
        "  x1 = l1 * jnp.sin(t1)\n",
        "  y1 = -l1 * jnp.cos(t1)\n",
        "  x2 = x1 + l2 * jnp.sin(t2)\n",
        "  y2 = y1 - l2 * jnp.cos(t2)\n",
        "  return x1, y1, x2, y2\n",
        "\n",
        "def write_to(data, path):\n",
        "  with open(path, 'wb') as f:\n",
        "    pickle.dump(data, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "\n",
        "def read_from(path):\n",
        "  with open(path, 'rb') as f:\n",
        "    data = pickle.load(f)\n",
        "  return data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "6XRq_Upmcetp"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "57OeKsfceAQT"
      },
      "source": [
        "# Physics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "AGvdboD-eCfQ"
      },
      "outputs": [],
      "source": [
        "# Generalized Lagrangian Networks | 2020\n",
        "# Miles Cranmer, Sam Greydanus, Stephan Hoyer (...)\n",
        "\n",
        "import jax\n",
        "import jax.numpy as jnp\n",
        "from jax import jit\n",
        "\n",
        "@jit\n",
        "def kinetic_energy(q, q_dot, m1=0.25, m2=1, l1=0.3, l2=1, g=9.8, I=0.0000125, d1=0.15):\n",
        "  t1, w1 = q, q_dot\n",
        "  T = 0.5 * (I + m1*(d1**2))*(w1**2)\n",
        "  return T\n",
        "\n",
        "@jit\n",
        "def potential_energy(q, q_dot, m1=0.25, m2=1, l1=0.3, l2=1, g=9.8, d1=0.15):\n",
        "  t1, w1 = q, q_dot\n",
        "  V = m1*g*l1*jnp.sin(t1)\n",
        "  return V\n",
        "\n",
        "# Double pendulum lagrangian\n",
        "@jit\n",
        "def lagrangian_fn(q, q_dot, m1=0.25, m2=1, l1=0.3, l2=1, g=9.8): #q_dot=0 to use with vfnc\n",
        "  T = kinetic_energy(q, q_dot, m1=1, m2=1, l1=1, l2=1, g=9.8)\n",
        "  V = potential_energy(q, q_dot, m1=1, m2=1, l1=1, l2=1, g=9.8)\n",
        "  return jnp.sum(T - V)\n",
        "\n",
        "@jit\n",
        "def analytical_fn(state, t=0, m1=0.25, m2=1, l1=0.3, l2=1, g=9.8, d1=0.15, I=0.0000125):\n",
        "  t1, w1 = state\n",
        "  a1 = 0\n",
        "  f1 = -m1*g*d1*jnp.cos(t1)/(I+m1*d1**2)\n",
        "  g1 = f1\n",
        "  return jnp.stack([w1,g1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ww1DfR68db4y"
      },
      "source": [
        "# Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6sOyFVymdFhu"
      },
      "outputs": [],
      "source": [
        "# Generalized Lagrangian Networks | 2020\n",
        "# Miles Cranmer, Sam Greydanus, Stephan Hoyer (...)\n",
        "\n",
        "import jax\n",
        "import jax.numpy as jnp\n",
        "from jax import random\n",
        "import numpy as np # get rid of this eventually\n",
        "from jax.experimental.ode import odeint\n",
        "from functools import partial # reduces arguments to function by making some subset implicit\n",
        "\n",
        "#import os, sys\n",
        "#THIS_DIR = os.path.dirname(os.path.abspath(__file__))\n",
        "#PARENT_DIR = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))\n",
        "#sys.path.append(PARENT_DIR)\n",
        "\n",
        "#from lnn import solve_dynamics\n",
        "#from utils import wrap_coords\n",
        "#HACK\n",
        "#from .physics import lagrangian_fn, analytical_fn\n",
        "#from physics import lagrangian_fn, analytical_fn\n",
        "\n",
        "\n",
        "@partial(jax.jit, backend='cpu')\n",
        "def get_trajectory(y0, times, use_lagrangian=False, **kwargs):\n",
        "  # frames = int(fps*(t_span[1]-t_span[0]))\n",
        "  # times = jnp.linspace(t_span[0], t_span[1], frames)\n",
        "  # y0 = np.array([3*np.pi/7, 3*np.pi/4, 0, 0], dtype=np.float32)\n",
        "  if use_lagrangian:\n",
        "    y = solve_dynamics(lagrangian_fn, y0, t=times, is_lagrangian=True, rtol=1e-10, atol=1e-10, **kwargs)\n",
        "  else:\n",
        "    y = odeint(analytical_fn, y0, t=times, rtol=1e-10, atol=1e-10, **kwargs)\n",
        "  return y\n",
        "\n",
        "@partial(jax.jit, backend='cpu')\n",
        "def get_trajectory_lagrangian(y0, times, **kwargs):\n",
        "  return solve_dynamics(lagrangian_fn, y0, t=times, is_lagrangian=True, rtol=1e-10, atol=1e-10, **kwargs)\n",
        "\n",
        "@partial(jax.jit, backend='cpu')\n",
        "def get_trajectory_analytic(y0, times, **kwargs):\n",
        "    return odeint(analytical_fn, y0, t=times, rtol=1e-10, atol=1e-10, **kwargs)\n",
        "\n",
        "def new_get_dataset(rng, samples=1, t_span=[0, 10], fps=100, test_split=0.5, lookahead=1,\n",
        "                    unlimited_steps=False, **kwargs):\n",
        "    data = {'meta': locals()}\n",
        "\n",
        "    # randomly sample inputs\n",
        "\n",
        "    frames = int(fps*(t_span[1]-t_span[0]))\n",
        "    times = jnp.linspace(t_span[0], t_span[1], frames)\n",
        "    y0 = jnp.concatenate([\n",
        "        jax.random.uniform(rng, (samples, 1))*2.0*np.pi,\n",
        "        jax.random.uniform(rng+1, (samples, 1))*0.1\n",
        "    ], axis=1)\n",
        "\n",
        "    if unlimited_steps:\n",
        "      y = vget(y0, times)\n",
        "    else:\n",
        "      y = vget_unlimited(y0, times)\n",
        "\n",
        "    #This messes it up!\n",
        "#     y = np.concatenate(((y[..., :2]%(2*np.pi)) - np.pi, y[..., 2:]), axis=2)\n",
        "\n",
        "    data['x'] = y[:, :-lookahead]\n",
        "    data['dx'] = y[:, lookahead:] - data['x']\n",
        "    data['x'] = jnp.concatenate(data['x'])\n",
        "    data['dx'] = jnp.concatenate(data['dx'])\n",
        "    data['t'] = jnp.tile(times[:-lookahead], (samples,))\n",
        "\n",
        "    # make a train/test split\n",
        "    split_ix = int(len(data['x']) * test_split)\n",
        "    split_data = {}\n",
        "    for k in ['x', 'dx', 't']:\n",
        "        split_data[k], split_data['test_' + k] = data[k][:split_ix], data[k][split_ix:]\n",
        "    data = split_data\n",
        "    return data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "umAM16BueXwf"
      },
      "source": [
        "# Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fpIG9arWeaki"
      },
      "outputs": [],
      "source": [
        "def extended_mlp(args):\n",
        "    act = {\n",
        "        'softplus': [Softplus, Softplus],\n",
        "        'swish': [Swish, Swish],\n",
        "        'tanh': [Tanh, Tanh],\n",
        "        'tanh_relu': [Tanh, Relu],\n",
        "        'soft_relu': [Softplus, Relu],\n",
        "        'relu_relu': [Relu, Relu],\n",
        "        'relu_relu3': [Relu, Relu3],\n",
        "        'relu3_relu': [Relu3, Relu],\n",
        "        'relu_tanh': [Relu, Tanh],\n",
        "    }[args.act]\n",
        "    hidden = args.hidden_dim\n",
        "    output_dim = args.output_dim\n",
        "    nlayers = args.layers\n",
        "\n",
        "    layers = []\n",
        "    layers.extend([\n",
        "        Dense(hidden),\n",
        "        act[0]\n",
        "    ])\n",
        "    for _ in range(nlayers - 1):\n",
        "        layers.extend([\n",
        "            Dense(hidden),\n",
        "            act[1]\n",
        "        ])\n",
        "\n",
        "    layers.extend([Dense(output_dim)])\n",
        "\n",
        "    return stax.serial(*layers)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train"
      ],
      "metadata": {
        "id": "8ZU4PL0wCbNq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import jax\n",
        "import jax.numpy as jnp\n",
        "from jax.tree_util import tree_flatten\n",
        "import numpy as np # get rid of this eventually\n",
        "import argparse\n",
        "from jax import jit\n",
        "from jax.experimental.ode import odeint\n",
        "from functools import partial # reduces arguments to function by making some subset implicit\n",
        "from jax.example_libraries import stax\n",
        "from jax.example_libraries import optimizers\n",
        "\n",
        "from jax.experimental.ode import odeint\n",
        "from jax.example_libraries.stax import serial, Dense, Softplus, Tanh, elementwise, Relu\n",
        "\n",
        "\n",
        "sigmoid = jit(lambda x: 1/(1+jnp.exp(-x)))\n",
        "swish = jit(lambda x: x/(1+jnp.exp(-x)))\n",
        "relu3 = jit(lambda x: jnp.clip(x, 0.0, float('inf'))**3)\n",
        "Swish = elementwise(swish)\n",
        "Relu3 = elementwise(relu3)\n",
        "\n",
        "vfnc = jax.jit(jax.vmap(analytical_fn))\n",
        "vget = partial(jax.jit, backend='cpu')(jax.vmap(partial(get_trajectory_analytic, mxstep=100), (0, None), 0))\n",
        "vget_unlimited = partial(jax.jit, backend='cpu')(jax.vmap(partial(get_trajectory_analytic), (0, None), 0))\n",
        "\n",
        "class ObjectView(object):\n",
        "    def __init__(self, d): self.__dict__ = d\n",
        "\n",
        "# replace the lagrangian with a parameteric model\n",
        "def learned_dynamics(params):\n",
        "  @jit\n",
        "  def dynamics(q, q_t):\n",
        "#     assert q.shape == (2,)\n",
        "    state = wrap_coords(jnp.concatenate([q, q_t]))\n",
        "    return jnp.squeeze(nn_forward_fn(params, state), axis=-1)\n",
        "  return dynamics\n",
        "\n",
        "\n",
        "def make_loss(args):\n",
        "    def baseline_loss(params, batch, time_step=None):\n",
        "      state, targets = batch\n",
        "      preds = jax.vmap(partial(unconstrained_eom, learned_dynamics(params)))(state)\n",
        "      #print(\"--------------------------Batch: \",len(batch))\n",
        "      #print(\"--------------------------State: \",state.shape)\n",
        "      #print(\"--------------------------Targets: \",targets.shape)\n",
        "      #print(\"--------------------------Preds: \",preds.shape)\n",
        "      return jnp.sqrt(jnp.mean((preds - targets) ** 2))\n",
        "    return baseline_loss\n",
        "\n",
        "from copy import deepcopy as copy\n",
        "from tqdm import tqdm\n",
        "\n",
        "def train(args, model, data, rng):\n",
        "    global opt_update, get_params, nn_forward_fn\n",
        "    global best_params, best_loss\n",
        "    best_params = None\n",
        "    best_loss = np.inf\n",
        "    best_small_loss = np.inf\n",
        "    (nn_forward_fn, init_params) = model\n",
        "    data = {k: jax.device_put(v) for k,v in data.items()}\n",
        "\n",
        "    loss = make_loss(args)\n",
        "    opt_init, opt_update, get_params = optimizers.adam(\n",
        "    lambda t: jnp.select([t  < args.num_epochs//2,\n",
        "                          t >= args.num_epochs//2],\n",
        "                         [args.lr, args.lr2]))\n",
        "    opt_state = opt_init(init_params)\n",
        "\n",
        "    @jax.jit\n",
        "    def update_derivative(i, opt_state, batch, l2reg):\n",
        "        params = get_params(opt_state)\n",
        "        return opt_update(i, jax.grad(loss, 0)(params, batch, l2reg), opt_state), params\n",
        "\n",
        "    train_losses, test_losses = [], []\n",
        "\n",
        "    for iteration in range(args.num_epochs):\n",
        "        rand_idx = jax.random.randint(rng, (args.batch_size,), 0, len(data['x']))\n",
        "        rng += 1\n",
        "\n",
        "        batch = (data['x'][rand_idx], data['dx'][rand_idx])\n",
        "        opt_state, params = update_derivative(iteration, opt_state, batch, args.l2reg)\n",
        "        small_loss = loss(params, batch, 0.0)\n",
        "\n",
        "        new_small_loss = False\n",
        "        if small_loss < best_small_loss:\n",
        "            best_small_loss = small_loss\n",
        "            new_small_loss = True\n",
        "\n",
        "        if new_small_loss or (iteration % 1000 == 0) or (iteration < 1000 and iteration % 100 == 0):\n",
        "          params = get_params(opt_state)\n",
        "          train_loss = loss(params, (data['x'], data['dx']), 0.0)/len(data['x'])\n",
        "          train_losses.append(train_loss)\n",
        "          test_loss = loss(params, (data['test_x'], data['test_dx']), 0.0)/len(data['test_x'])\n",
        "          test_losses.append(test_loss)\n",
        "\n",
        "          if test_loss < best_loss:\n",
        "              best_loss = test_loss\n",
        "              best_params = params\n",
        "\n",
        "          if jnp.isnan(test_loss).sum():\n",
        "              break\n",
        "\n",
        "        #print(f\"iteration={iteration}, train_loss={train_loss:.6f}, test_loss={test_loss:.6f}\")\n",
        "          print(f\"-------> New best loss! Train_loss={train_loss:.6f}, Test_loss={test_loss:.6f}\")\n",
        "        print(f\"Epoch: {iteration}/{args.num_epochs}\")\n",
        "\n",
        "    params = get_params(opt_state)\n",
        "    return params, train_losses, test_losses, best_loss\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "\n",
        "args = ObjectView(dict(\n",
        "    num_epochs=40000, #100,40000\n",
        "    loss='l1',\n",
        "    l2reg=1e-6,\n",
        "    act='softplus',\n",
        "    hidden_dim=300,\n",
        "    output_dim=1,\n",
        "    dt=1e-1,\n",
        "    layers=4,\n",
        "    lr=1e-3*0.5,\n",
        "    lr2=1e-4*0.5,\n",
        "    model='gln',\n",
        "    n_updates=3,\n",
        "    batch_size=32,\n",
        "    fps=10,\n",
        "    samples=50,\n",
        "    dataset_size=300,\n",
        "))\n",
        "\n",
        "def test_args(args):\n",
        "  print('Running on', args.__dict__)\n",
        "  rng = jax.random.PRNGKey(0)\n",
        "  init_random_params, nn_forward_fn = extended_mlp(args)\n",
        "  _, init_params = init_random_params(rng+1, (-1, 2)) #4\n",
        "  model = (nn_forward_fn, init_params)\n",
        "\n",
        "  data = new_get_dataset(jax.random.PRNGKey(0), t_span=[0, args.dataset_size], fps=args.fps, samples=args.samples, test_split=0.7)\n",
        "\n",
        "  result = train(args, model, data, rng+3)\n",
        "  print(result[3], 'is the loss for', args.__dict__)\n",
        "\n",
        "  fig, ax = plt.subplots(1, 1)\n",
        "\n",
        "  ax.plot(result[1], label='Train loss')\n",
        "  ax.plot(result[2], label='Test loss')\n",
        "  ax.set_ylabel(\"Loss\")\n",
        "  ax.set_xlabel(\"Epochs\")\n",
        "  ax.legend()\n",
        "\n",
        "  fig.tight_layout()\n",
        "\n",
        "  if not jnp.isfinite(result[3]).sum():\n",
        "      return {'status': 'fail', 'loss': float('inf')}\n",
        "\n",
        "  pickle.dump({'params': best_params, 'args': args},open('/content/drive/MyDrive/Robotics_2/1R_rigid_vertical/params_for_loss_{}_nupdates=1.pkl'.format(best_loss), 'wb'))\n",
        "\n",
        "  return {'status': 'ok', 'loss': float(result[3])}\n",
        "\n",
        "test_args(args)\n",
        "#\n",
        "#best_params = pkl.load(\n",
        "#    open('best_dblpendulum_baseline_v5_900epoch.pt', 'rb')\n",
        "#)\n",
        "# p = get_params(opt_state)\n",
        "#opt_state = opt_init(best_params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 608
        },
        "id": "Xwr9g0gW8zbi",
        "outputId": "1e01516d-6716-4e2c-e61a-5d442c248446"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running on {'num_epochs': 40000, 'loss': 'l1', 'l2reg': 1e-06, 'act': 'softplus', 'hidden_dim': 300, 'output_dim': 1, 'dt': 0.1, 'layers': 4, 'lr': 0.0005, 'lr2': 5e-05, 'model': 'gln', 'n_updates': 3, 'batch_size': 32, 'fps': 10, 'samples': 50, 'dataset_size': 300}\n",
            "-------> New best loss! Train_loss=0.000048, Test_loss=0.000114\n",
            "Epoch: 0/40000\n",
            "Epoch: 1/40000\n",
            "Epoch: 2/40000\n",
            "Epoch: 3/40000\n",
            "Epoch: 4/40000\n",
            "Epoch: 5/40000\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-6f0474133cf3>\u001b[0m in \u001b[0;36m<cell line: 161>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    159\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'status'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'ok'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'loss'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 161\u001b[0;31m \u001b[0mtest_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    162\u001b[0m \u001b[0;31m#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[0;31m#best_params = pkl.load(\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-8-6f0474133cf3>\u001b[0m in \u001b[0;36mtest_args\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m    139\u001b[0m   \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_get_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPRNGKey\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt_span\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msamples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.7\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m   \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrng\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'is the loss for'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-8-6f0474133cf3>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(args, model, data, rng)\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnew_small_loss\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0miteration\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m1000\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0miteration\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1000\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0miteration\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m100\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m           \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopt_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m           \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'x'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'dx'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'x'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m           \u001b[0mtrain_losses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m           \u001b[0mtest_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'test_x'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'test_dx'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'test_x'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-8-6f0474133cf3>\u001b[0m in \u001b[0;36mbaseline_loss\u001b[0;34m(params, batch, time_step)\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mbaseline_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime_step\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m       \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m       \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpartial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munconstrained_eom\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearned_dynamics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m       \u001b[0;31m#print(\"--------------------------Batch: \",len(batch))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m       \u001b[0;31m#print(\"--------------------------State: \",state.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/jax/_src/api.py\u001b[0m in \u001b[0;36mvmap_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1237\u001b[0m     axis_size_ = (axis_size if axis_size is not None else\n\u001b[1;32m   1238\u001b[0m                   _mapped_axis_size(fun, in_tree, args_flat, in_axes_flat, \"vmap\"))\n\u001b[0;32m-> 1239\u001b[0;31m     out_flat = batching.batch(\n\u001b[0m\u001b[1;32m   1240\u001b[0m         \u001b[0mflat_fun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis_size_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_axes_flat\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1241\u001b[0m         \u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mflatten_axes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"vmap out_axes\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_tree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_axes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/jax/_src/linear_util.py\u001b[0m in \u001b[0;36mcall_wrapped\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m       \u001b[0mans\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m     \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m       \u001b[0;31m# Some transformations yield from inside context managers, so we have to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-2-11400339c3c2>\u001b[0m in \u001b[0;36munconstrained_eom\u001b[0;34m(model, state, t)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0munconstrained_eom\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m   \u001b[0mq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mq_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mjnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mq_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mq_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m# lagrangian equation of motion\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/jax/_src/pjit.py\u001b[0m in \u001b[0;36mcache_miss\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    206\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mapi_boundary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcache_miss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m     outs, out_flat, out_tree, args_flat = _python_pjit_helper(\n\u001b[0m\u001b[1;32m    209\u001b[0m         fun, infer_params_fn, *args, **kwargs)\n\u001b[1;32m    210\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/jax/_src/pjit.py\u001b[0m in \u001b[0;36m_python_pjit_helper\u001b[0;34m(fun, infer_params_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    153\u001b[0m     \u001b[0mdispatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_arg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 155\u001b[0;31m     \u001b[0mout_flat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpjit_p\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs_flat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    156\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mpxla\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDeviceAssignmentMismatchError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m     \u001b[0mfails\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/jax/_src/core.py\u001b[0m in \u001b[0;36mbind\u001b[0;34m(self, *args, **params)\u001b[0m\n\u001b[1;32m   2631\u001b[0m     top_trace = (top_trace if not axis_main or axis_main.level < top_trace.level\n\u001b[1;32m   2632\u001b[0m                  else axis_main.with_cur_sublevel())\n\u001b[0;32m-> 2633\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind_with_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtop_trace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2634\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2635\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/jax/_src/core.py\u001b[0m in \u001b[0;36mbind_with_trace\u001b[0;34m(self, trace, args, params)\u001b[0m\n\u001b[1;32m    381\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mbind_with_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 383\u001b[0;31m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_primitive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfull_raise\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    384\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfull_lower\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmultiple_results\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mfull_lower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    385\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/jax/_src/interpreters/batching.py\u001b[0m in \u001b[0;36mprocess_primitive\u001b[0;34m(self, primitive, tracers, params)\u001b[0m\n\u001b[1;32m    361\u001b[0m       \u001b[0mframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvals_in\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdims_in\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m       \u001b[0mbatched_primitive\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_primitive_batcher\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprimitive\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 363\u001b[0;31m       \u001b[0mval_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatched_primitive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvals_in\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdims_in\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    364\u001b[0m     \u001b[0msrc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msource_info_util\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mprimitive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmultiple_results\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/jax/_src/pjit.py\u001b[0m in \u001b[0;36m_pjit_batcher\u001b[0;34m(insert_axis, spmd_axis_name, axis_size, axis_name, main_type, vals_in, dims_in, jaxpr, in_shardings, out_shardings, resource_env, donated_invars, name, keep_unused, inline)\u001b[0m\n\u001b[1;32m   1359\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0maxis_out\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1360\u001b[0m       for axis_out, o, aval in zip(axes_out, out_shardings, new_jaxpr.out_avals))\n\u001b[0;32m-> 1361\u001b[0;31m   vals_out = pjit_p.bind(\n\u001b[0m\u001b[1;32m   1362\u001b[0m     \u001b[0;34m*\u001b[0m\u001b[0mvals_in\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1363\u001b[0m     \u001b[0mjaxpr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnew_jaxpr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/jax/_src/core.py\u001b[0m in \u001b[0;36mbind\u001b[0;34m(self, *args, **params)\u001b[0m\n\u001b[1;32m   2631\u001b[0m     top_trace = (top_trace if not axis_main or axis_main.level < top_trace.level\n\u001b[1;32m   2632\u001b[0m                  else axis_main.with_cur_sublevel())\n\u001b[0;32m-> 2633\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind_with_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtop_trace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2634\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2635\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/jax/_src/core.py\u001b[0m in \u001b[0;36mbind_with_trace\u001b[0;34m(self, trace, args, params)\u001b[0m\n\u001b[1;32m    381\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mbind_with_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 383\u001b[0;31m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_primitive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfull_raise\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    384\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfull_lower\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmultiple_results\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mfull_lower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    385\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/jax/_src/core.py\u001b[0m in \u001b[0;36mprocess_primitive\u001b[0;34m(self, primitive, tracers, params)\u001b[0m\n\u001b[1;32m    788\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    789\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mprocess_primitive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprimitive\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtracers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 790\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mprimitive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimpl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mtracers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    791\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    792\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mprocess_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprimitive\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtracers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/jax/_src/pjit.py\u001b[0m in \u001b[0;36m_pjit_call_impl\u001b[0;34m(jaxpr, in_shardings, out_shardings, resource_env, donated_invars, name, keep_unused, inline, *args)\u001b[0m\n\u001b[1;32m   1106\u001b[0m                           (\"fingerprint\", fingerprint))\n\u001b[1;32m   1107\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1108\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcompiled\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsafe_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1109\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mFloatingPointError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1110\u001b[0m     \u001b[0;32massert\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjax_debug_nans\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjax_debug_infs\u001b[0m  \u001b[0;31m# compiled_fun can only raise in this case\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/jax/_src/profiler.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    312\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mTraceAnnotation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mdecorator_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 314\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    315\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/jax/_src/interpreters/pxla.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1344\u001b[0m           results.consume_token())\n\u001b[1;32m   1345\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1346\u001b[0;31m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxla_executable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute_sharded\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_bufs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1347\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdispatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mneeds_check_special\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1348\u001b[0m       \u001b[0mout_arrays\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisassemble_into_single_device_arrays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "aSH3UDxeii7B",
        "4dlBAEyodLjY",
        "-hTiSIu4d1Rc",
        "ww1DfR68db4y",
        "umAM16BueXwf"
      ],
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}