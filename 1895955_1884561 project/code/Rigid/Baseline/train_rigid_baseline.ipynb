{"cells":[{"cell_type":"markdown","metadata":{"id":"aSH3UDxeii7B"},"source":["# Global"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":15671,"status":"ok","timestamp":1689490960721,"user":{"displayName":"claudio schiavella","userId":"11074666491842407425"},"user_tz":-120},"id":"yTFM_ZnZWr9o","outputId":"984a5115-4ded-4722-c66d-8964a1fed8f7"},"outputs":[],"source":["try:\n","    from google.colab import drive\n","    drive.mount('/content/drive')\n","    root_path = \"/content/drive/MyDrive/Try_Robotics2_project/\"\n","except:\n","    root_path = \"./\""]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":11,"status":"ok","timestamp":1689490960723,"user":{"displayName":"claudio schiavella","userId":"11074666491842407425"},"user_tz":-120},"id":"HElFeDMTWr9q"},"outputs":[],"source":["global opt_update, get_params, nn_forward_fn\n","global best_params, best_loss\n","\n","# Arguments encoder\n","class ObjectView(object):\n","    def __init__(self, d): self.__dict__ = d\n","\n","args = ObjectView(dict(\n","    num_epochs=10000,\n","    loss='baseline_nn',\n","    l2reg=1e-6,\n","    act='softplus',\n","    hidden_dim=500,\n","    output_dim=1,\n","    dt=1e-1,\n","    layers=4,\n","    lr=1e-3*0.5,\n","    lr2=1e-4*0.5,\n","    model='gln',\n","    n_updates=3,\n","    batch_size=32,\n","    fps=10,\n","    samples=300,\n","    dataset_size=300,\n","))"]},{"cell_type":"markdown","metadata":{"id":"E5pgoIyxWr9r"},"source":["# Imports"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":403,"status":"ok","timestamp":1689490961118,"user":{"displayName":"claudio schiavella","userId":"11074666491842407425"},"user_tz":-120},"id":"BgtP6IYWWr9s"},"outputs":[],"source":["import argparse\n","import jax\n","import jax.numpy as jnp\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import pickle as pkl\n","\n","from copy import deepcopy as copy\n","from functools import partial\n","from jax import jit\n","from jax import random\n","from jax.example_libraries import stax\n","from jax.example_libraries.stax import serial, Dense, Softplus, Tanh, elementwise, Relu\n","from jax.example_libraries import optimizers\n","from jax.experimental.ode import odeint\n","from jax.tree_util import tree_flatten\n","from tqdm import tqdm"]},{"cell_type":"markdown","metadata":{"id":"-hTiSIu4d1Rc"},"source":["# Utils"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":267,"status":"ok","timestamp":1689491579948,"user":{"displayName":"claudio schiavella","userId":"11074666491842407425"},"user_tz":-120},"id":"5D81fQLgdFW3"},"outputs":[],"source":["def wrap_coords(state):\n","  return jnp.concatenate([(state[:2] + jnp.pi) % (2 * jnp.pi) - jnp.pi, state[2:]])\n","\n","def rk4_step(f, x, t, h):\n","  k1 = h * f(x, t)\n","  k2 = h * f(x + k1/2, t + h/2)\n","  k3 = h * f(x + k2/2, t + h/2)\n","  k4 = h * f(x + k3, t + h)\n","  return x + 1/6 * (k1 + 2 * k2 + 2 * k3 + k4)\n","\n","def radial2cartesian(t1, t2, l1, l2):\n","  x1 = l1 * jnp.sin(t1)\n","  y1 = -l1 * jnp.cos(t1)\n","  x2 = x1 + l2 * jnp.sin(t2)\n","  y2 = y1 - l2 * jnp.cos(t2)\n","  return x1, y1, x2, y2\n","\n","def write_to(data, path):\n","  with open(path, 'wb') as f:\n","    pkl.dump(data, f, protocol=pkl.HIGHEST_PROTOCOL)\n","\n","def read_from(path):\n","  with open(path, 'rb') as f:\n","    data = pkl.load(f)\n","  return data\n","\n","def plot_loss(train_losses, test_losses, updates):\n","  length = range(0,len(train_losses)+1,10)\n","\n","  fig, ax = plt.subplots(1, 1)\n","  plt.title(\"Rigid baseline loss\")\n","\n","  ax.plot(train_losses, label='Train loss')\n","  ax.plot(test_losses, label='Test loss')\n","  ax.set_xticks(length)\n","  ax.set_ylabel(\"Loss\")\n","  ax.set_xlabel(\"Updates\")\n","  ax.legend()\n","\n","  fig.tight_layout()"]},{"cell_type":"markdown","metadata":{"id":"4dlBAEyodLjY"},"source":["# Lagrangian Dynamics"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1689490961387,"user":{"displayName":"claudio schiavella","userId":"11074666491842407425"},"user_tz":-120},"id":"fFWTbEPCdFpQ"},"outputs":[],"source":["def unconstrained_eom(model, state, t=None):\n","  q, q_t = jnp.split(state, 2)\n","  return jnp.concatenate([q_t, model(q, q_t).reshape([1])])\n","\n","def lagrangian_eom(lagrangian, state, t=None):\n","  q, q_t = jnp.split(state, 2)\n","  q = q % (2*jnp.pi)\n","  q_tt = (jnp.linalg.pinv(jax.hessian(lagrangian, 1)(q, q_t))\n","          @ (jax.grad(lagrangian, 0)(q, q_t)\n","             - jax.jacobian(jax.jacobian(lagrangian, 1), 0)(q, q_t) @ q_t))\n","  dt = 1e-1\n","  return dt*jnp.concatenate([q_t, q_tt])\n","\n","def raw_lagrangian_eom(lagrangian, state, t=None):\n","  q, q_t = jnp.split(state, 2)\n","  q = q % (2*jnp.pi)\n","  q_tt = (jnp.linalg.pinv(jax.hessian(lagrangian, 1)(q, q_t))\n","          @ (jax.grad(lagrangian, 0)(q, q_t)\n","             - jax.jacobian(jax.jacobian(lagrangian, 1), 0)(q, q_t) @ q_t))\n","  return jnp.concatenate([q_t, q_tt])\n","\n","def lagrangian_eom_rk4(lagrangian, state, n_updates, Dt=1e-1, t=None):\n","    @jax.jit\n","    def cur_fnc(state):\n","        q, q_t = jnp.split(state, 2)\n","        q = q % (2*jnp.pi)\n","        q_tt = (jnp.linalg.pinv(jax.hessian(lagrangian, 1)(q, q_t))\n","                 @ (jax.grad(lagrangian, 0)(q, q_t)\n","                 - jax.jacobian(jax.jacobian(lagrangian, 1), 0)(q, q_t) @ q_t))\n","        return jnp.concatenate([q_t, q_tt])\n","\n","    @jax.jit\n","    def get_update(update):\n","        dt = Dt/n_updates\n","        cstate = state + update\n","        k1 = dt*cur_fnc(cstate)\n","        k2 = dt*cur_fnc(cstate + k1/2)\n","        k3 = dt*cur_fnc(cstate + k2/2)\n","        k4 = dt*cur_fnc(cstate + k3)\n","        return update + 1.0/6.0 * (k1 + 2*k2 + 2*k3 + k4)\n","\n","    update = 0\n","    for _ in range(n_updates):\n","        update = get_update(update)\n","    return update\n","\n","\n","def solve_dynamics(dynamics_fn, initial_state, is_lagrangian=True, **kwargs):\n","  eom = lagrangian_eom if is_lagrangian else unconstrained_eom\n","\n","  @partial(jax.jit, backend='cpu')\n","  def f(initial_state):\n","    return odeint(partial(eom, dynamics_fn), initial_state, **kwargs)\n","  return f(initial_state)\n","\n","\n","def custom_init(init_params, seed=0):\n","    import numpy as np\n","    new_params = []\n","    rng = jax.random.PRNGKey(seed)\n","    i = 0\n","    number_layers = len([0 for l1 in init_params if len(l1) != 0])\n","    for l1 in init_params:\n","        if (len(l1)) == 0: new_params.append(()); continue\n","        new_l1 = []\n","        for l2 in l1:\n","            if len(l2.shape) == 1:\n","                new_l1.append(jnp.zeros_like(l2))\n","            else:\n","                n = max(l2.shape)\n","                first = int(i == 0)\n","                last = int(i == number_layers - 1)\n","                mid = int((i != 0) * (i != number_layers - 1))\n","                mid *= i\n","\n","                std = 1.0/np.sqrt(n)\n","                std *= 2.2*first + 0.58*mid + n*last\n","\n","                if std == 0:\n","                    raise NotImplementedError(\"Wrong dimensions for MLP\")\n","\n","                new_l1.append(jax.random.normal(rng, l2.shape)*std)\n","                rng += 1\n","                i += 1\n","\n","        new_params.append(new_l1)\n","\n","    return new_params"]},{"cell_type":"markdown","metadata":{"id":"57OeKsfceAQT"},"source":["# Physics"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1689490965410,"user":{"displayName":"claudio schiavella","userId":"11074666491842407425"},"user_tz":-120},"id":"AGvdboD-eCfQ"},"outputs":[],"source":["@jit\n","def test_kinetic_energy(state, m1=0.25, l1=0.3, g=9.81, I=0.01125, d1=0.15):\n","    q, q_dot = jnp.split(state, 2)\n","    t1, w1 = q, q_dot\n","    T = 0.5 * (I + m1*(d1**2))*(w1**2)\n","    return T\n","\n","@jit\n","def test_potential_energy(state, m1=0.25, l1=0.3, g=9.81, I=0.01125, d1=0.15):\n","    q, q_dot = jnp.split(state, 2)\n","    t1, w1 = q, q_dot\n","    V = -m1*g*d1*jnp.cos(t1)\n","    return V\n","\n","@jit\n","def kinetic_energy(q, q_dot, m1=0.25, l1=0.3, g=9.81, I=0.01125, d1=0.15):\n","  t1, w1 = q, q_dot\n","  T = 0.5 * (I + m1*(d1**2))*(w1**2)\n","  return T\n","\n","@jit\n","def potential_energy(q, q_dot, m1=0.25, l1=0.3, g=9.81, I=0.01125, d1=0.15):\n","  t1, w1 = q, q_dot\n","  V = -m1*g*d1*jnp.cos(t1)\n","  return V\n","\n","@jit\n","def lagrangian_fn(q, q_dot, m1=0.25, l1=0.3, g=9.81, I=0.01125, d1=0.15):\n","  T = kinetic_energy(q, q_dot)\n","  V = potential_energy(q, q_dot)\n","  return jnp.sum(T - V)\n","\n","@jit\n","def analytical_fn(state, t=0, m1=0.25, l1=0.3, g=9.81, I=0.01125, d1=0.15):\n","  t1, w1 = state\n","  a1 = 0\n","  f1 = -m1*g*d1*jnp.sin(t1)/(I+m1*(d1**2))\n","  g1 = f1\n","  return jnp.stack([w1,g1])"]},{"cell_type":"markdown","metadata":{"id":"ww1DfR68db4y"},"source":["# Data"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":260,"status":"ok","timestamp":1689490966984,"user":{"displayName":"claudio schiavella","userId":"11074666491842407425"},"user_tz":-120},"id":"6sOyFVymdFhu"},"outputs":[],"source":["@partial(jax.jit, backend='cpu')\n","def get_trajectory(y0, times, use_lagrangian=False, **kwargs):\n","  if use_lagrangian:\n","    y = solve_dynamics(lagrangian_fn, y0, t=times, is_lagrangian=True, rtol=1e-10, atol=1e-10, **kwargs)\n","  else:\n","    y = odeint(analytical_fn, y0, t=times, rtol=1e-10, atol=1e-10, **kwargs)\n","  return y\n","\n","@partial(jax.jit, backend='cpu')\n","def get_trajectory_lagrangian(y0, times, **kwargs):\n","  return solve_dynamics(lagrangian_fn, y0, t=times, is_lagrangian=True, rtol=1e-10, atol=1e-10, **kwargs)\n","\n","@partial(jax.jit, backend='cpu')\n","def get_trajectory_analytic(y0, times, **kwargs):\n","    return odeint(analytical_fn, y0, t=times, rtol=1e-10, atol=1e-10, **kwargs)\n","\n","def new_get_dataset(rng, samples=1, t_span=[0, 10], fps=100, test_split=0.5, lookahead=1,\n","                    unlimited_steps=False, **kwargs):\n","    data = {'meta': locals()}\n","    vfnc = jax.jit(jax.vmap(analytical_fn))\n","    vget = partial(jax.jit, backend='cpu')(jax.vmap(partial(get_trajectory_analytic, mxstep=100), (0, None), 0))\n","    vget_unlimited = partial(jax.jit, backend='cpu')(jax.vmap(partial(get_trajectory_analytic), (0, None), 0))\n","\n","    frames = int(fps*(t_span[1]-t_span[0]))\n","    times = jnp.linspace(t_span[0], t_span[1], frames)\n","    y0 = jnp.concatenate([\n","        jax.random.uniform(rng, (samples, 1))*2.0*np.pi,\n","        jax.random.uniform(rng+1, (samples, 1))*0.1\n","    ], axis=1)\n","\n","    if unlimited_steps:\n","      y = vget(y0, times)\n","    else:\n","      y = vget_unlimited(y0, times)\n","\n","    data['x'] = y[:, :-lookahead]\n","    data['dx'] = y[:, lookahead:] - data['x']\n","    data['x'] = jnp.concatenate(data['x'])\n","    data['dx'] = jnp.concatenate(data['dx'])\n","    data['t'] = jnp.tile(times[:-lookahead], (samples,))\n","\n","    split_ix = int(len(data['x']) * test_split)\n","    split_data = {}\n","    for k in ['x', 'dx', 't']:\n","        split_data[k], split_data['test_' + k] = data[k][:split_ix], data[k][split_ix:]\n","    data = split_data\n","    return data"]},{"cell_type":"markdown","metadata":{"id":"umAM16BueXwf"},"source":["# Models"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1689490967987,"user":{"displayName":"claudio schiavella","userId":"11074666491842407425"},"user_tz":-120},"id":"fpIG9arWeaki"},"outputs":[],"source":["sigmoid = jit(lambda x: 1/(1+jnp.exp(-x)))\n","swish = jit(lambda x: x/(1+jnp.exp(-x)))\n","relu3 = jit(lambda x: jnp.clip(x, 0.0, float('inf'))**3)\n","Swish = elementwise(swish)\n","Relu3 = elementwise(relu3)\n","\n","def extended_mlp(args):\n","    act = {\n","        'softplus': [Softplus, Softplus],\n","        'swish': [Swish, Swish],\n","        'tanh': [Tanh, Tanh],\n","        'tanh_relu': [Tanh, Relu],\n","        'soft_relu': [Softplus, Relu],\n","        'relu_relu': [Relu, Relu],\n","        'relu_relu3': [Relu, Relu3],\n","        'relu3_relu': [Relu3, Relu],\n","        'relu_tanh': [Relu, Tanh],\n","    }[args.act]\n","    hidden = args.hidden_dim\n","    output_dim = args.output_dim\n","    nlayers = args.layers\n","\n","    layers = []\n","    layers.extend([\n","        Dense(hidden),\n","        act[0]\n","    ])\n","    for _ in range(nlayers - 1):\n","        layers.extend([\n","            Dense(hidden),\n","            act[1]\n","        ])\n","\n","    layers.extend([Dense(output_dim)])\n","\n","    return stax.serial(*layers)"]},{"cell_type":"markdown","metadata":{"id":"rYl6IRp0Wr9z"},"source":["# Loss"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1689490969048,"user":{"displayName":"claudio schiavella","userId":"11074666491842407425"},"user_tz":-120},"id":"CDQtPQdeWr9z"},"outputs":[],"source":["def learned_dynamics(params):\n","  @jit\n","  def dynamics(q, q_t):\n","    state = wrap_coords(jnp.concatenate([q, q_t]))\n","    return jnp.squeeze(nn_forward_fn(params, state), axis=-1)\n","  return dynamics\n","\n","def make_loss(args):\n","    if args.loss == 'lnn':\n","        @jax.jit\n","        def gln_loss(params, batch, l2reg):\n","            state, targets = batch#_rk4\n","            leaves, _ = tree_flatten(params)\n","            l2_norm = sum(jnp.vdot(param, param) for param in leaves)\n","            preds = jax.vmap(partial(lagrangian_eom_rk4, learned_dynamics(params), Dt=args.dt, n_updates=args.n_updates))(state)\n","            return jnp.sum(jnp.abs(preds - targets)) + l2reg*l2_norm/args.batch_size\n","\n","    elif args.loss == 'baseline_nn':\n","        @jax.jit\n","        def gln_loss(params, batch, l2reg):\n","          state, targets = batch\n","          preds = jax.vmap(partial(unconstrained_eom, learned_dynamics(params)))(state)\n","          return jnp.sum(jnp.abs(preds - targets)) + l2reg/args.batch_size\n","\n","    else:\n","        print(\"---------------------- SELECT A CORRECT LOSS ----------------------\")\n","        exit(0)\n","\n","    return gln_loss"]},{"cell_type":"markdown","metadata":{"id":"8ZU4PL0wCbNq"},"source":["# Train"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":204638,"status":"ok","timestamp":1689491427312,"user":{"displayName":"claudio schiavella","userId":"11074666491842407425"},"user_tz":-120},"id":"Xwr9g0gW8zbi","outputId":"3d225805-4409-4fa5-eac0-c63ed456c35b"},"outputs":[],"source":["def train(args, model, data, rng):\n","    global opt_update, get_params, nn_forward_fn\n","    global best_params, best_loss\n","\n","    model_checkpoint = root_path + \"Rigid/Baseline/\" + args.loss + \"_new_rigid_params.pkl\"\n","\n","    best_params = None\n","    best_loss = np.inf\n","    best_small_loss = np.inf\n","    (nn_forward_fn, init_params) = model\n","    data = {k: jax.device_put(v) for k,v in data.items()}\n","\n","    loss = make_loss(args)\n","    opt_init, opt_update, get_params = optimizers.adam(\n","    lambda t: jnp.select([t  < args.num_epochs//2,\n","                          t >= args.num_epochs//2],\n","                         [args.lr, args.lr2]))\n","    opt_state = opt_init(init_params)\n","\n","    @jax.jit\n","    def update_derivative(i, opt_state, batch, l2reg):\n","        params = get_params(opt_state)\n","        return opt_update(i, jax.grad(loss, 0)(params, batch, l2reg), opt_state), params\n","\n","    train_losses, test_losses, epochs_update = [], [], []\n","\n","    print(\"####################################### Train start #######################################\")\n","    for iteration in range(args.num_epochs):\n","        rand_idx = jax.random.randint(rng, (args.batch_size,), 0, len(data['x']))\n","        rng += 1\n","\n","        batch = (data['x'][rand_idx], data['dx'][rand_idx])\n","        opt_state, params = update_derivative(iteration, opt_state, batch, args.l2reg)\n","        small_loss = loss(params, batch, 0.0)\n","\n","        new_small_loss = False\n","        if small_loss < best_small_loss:\n","            best_small_loss = small_loss\n","            new_small_loss = True\n","\n","        if new_small_loss or (iteration % 1000 == 0) or (iteration < 1000 and iteration % 100 == 0):\n","          params = get_params(opt_state)\n","          train_loss = loss(params, (data['x'], data['dx']), 0.0)/len(data['x'])\n","          train_losses.append(train_loss)\n","          test_loss = loss(params, (data['test_x'], data['test_dx']), 0.0)/len(data['test_x'])\n","          test_losses.append(test_loss)\n","\n","          epochs_update.append(iteration)\n","\n","          if test_loss < best_loss:\n","              best_loss = test_loss\n","              best_params = params\n","\n","          if jnp.isnan(test_loss).sum():\n","              break\n","\n","          print(f\"-------> New best loss! Train_loss={train_loss:.6f}, Test_loss={test_loss:.6f}\")\n","        print(f\"Epoch: {iteration}/{args.num_epochs}\")\n","\n","    params = get_params(opt_state)\n","    write_to({'params': best_params, 'args': args},model_checkpoint)\n","    print(\"####################################### Train end #######################################\")\n","    print(\"--- Best loss: \", best_loss)\n","\n","    return params, train_losses, test_losses, epochs_update\n","\n","print('Globals:', args.__dict__)\n","rng = jax.random.PRNGKey(0)\n","init_random_params, nn_forward_fn = extended_mlp(args)\n","_, init_params = init_random_params(rng+1, (-1, 2)) #4\n","model = (nn_forward_fn, init_params)\n","data = new_get_dataset(jax.random.PRNGKey(0), t_span=[0, args.dataset_size], fps=args.fps, samples=args.samples, test_split=0.7)\n","result = train(args, model, data, rng+3)\n","anchor = model_checkpoint = root_path + \"Rigid/Baseline/\" + args.loss + \"_new_train_backup.pkl\"\n","write_to({'train' : result[1], 'test' : result[2], 'update': result[3]},anchor)\n","plot_loss(result[1],result[2],result[3])"]}],"metadata":{"colab":{"collapsed_sections":["aSH3UDxeii7B","E5pgoIyxWr9r","-hTiSIu4d1Rc","4dlBAEyodLjY","57OeKsfceAQT","ww1DfR68db4y","umAM16BueXwf","rYl6IRp0Wr9z"],"gpuType":"T4","machine_shape":"hm","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.4"}},"nbformat":4,"nbformat_minor":0}
